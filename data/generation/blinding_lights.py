# blinding_lights.py
# 
# Produce sequences of "on" and "off" lights, paired with a quantified expression
# describing how many lights are on.
# 
#   üí° üí° üí° ‚ö´Ô∏è   ->    most lights are on
#   üí° üí° üí° üí°   ->    all lights are on
#   üí° üí° ‚ö´Ô∏è ‚ö´Ô∏è   ->    some lights are on
#   ‚ö´Ô∏è ‚ö´Ô∏è ‚ö´Ô∏è ‚ö´Ô∏è   ->    no lights are on
#   üí° ‚ö´Ô∏è ‚ö´Ô∏è ‚ö´Ô∏è   ->    few lights are on
# 
# From this we can test generalization to longer (or shorter) lengths, out-of-order 
# sequences (i.e., train on having all the "on" lights be first and then test what 
# happens when the lights are out of order)

import numpy as np
from emoji import UNICODE_EMOJI

def get_quantifier(on: int, total: int):

  if on == 0:
    return "None"
  elif on == total:
    return "All"
  else:
    prop = float(on) / float(total)
    if prop > 0.5:
      return "Most"
    else:
      return "Some"

def add_space(text):
    return ''.join(' ' + char if char in UNICODE_EMOJI else char for char in text).strip()

def generate_sequences(outfile: str):

  ON = u"üí°"
  OFF = u"‚ö´Ô∏è"

  MAX_LENGTH = 10
  NUM_SENTENCES = 10_000

  lengths = np.random.randint(1, MAX_LENGTH, size=NUM_SENTENCES)
  num_on = np.random.randint(0, lengths + 1)

  with open(outfile, 'w') as f:
    f.write("source\ttransformation\ttarget\n")
  
  with open(outfile, 'a') as f:
    for i in range(NUM_SENTENCES):
      on_lights = ON * num_on[i]
      off_lights = OFF * (lengths[i] - num_on[i])
      lights = add_space(on_lights + off_lights)
      # print([ord(l) for l in lights.split()])
      quant = get_quantifier(num_on[i], lengths[i])
      target = f"{quant} of the lights are on"
      f.write(f"{lights}\tquant\t{target}\n")

def main():
  generate_sequences("data/raw/lights.tsv")

if __name__ == "__main__":
  main()
